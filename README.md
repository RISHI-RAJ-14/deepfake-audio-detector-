# ğŸ™ï¸ Deepfake Audio Detection for KYC Authentication

Detect and explain **AI-generated (deepfake) voices** using a **CNNâ€“LSTM model**, audio forensics, and explainability visualization â€” all in an interactive **Streamlit web app**.

ğŸ”— **Live Demo:** [https://ruhkjhtofjqcjwprzkabmc.streamlit.app/](https://ruhkjhtofjqcjwprzkabmc.streamlit.app/)

---

## ğŸš€ Features

| Category | Description |
|-----------|--------------|
| ğŸ§ **Single Audio Detection** | Upload an audio clip and get a real/fake prediction with model confidence |
| âš–ï¸ **Audio Comparison Mode** | Compare real and fake audios side by side with synchronized visualizations |
| ğŸ”¥ **Explainability (Grad-CAM)** | View heatmaps showing which spectrogram regions influenced model decisions |
| ğŸ” **Forensic Analysis** | Examine handcrafted forensic metrics â€” spectral bursts, pitch jitter, harmonicity, etc. |
| ğŸ§  **Advanced Feature Extraction** | Visualize MFCCs, spectral roll-off, pitch contour, and other advanced audio features |

---

## ğŸ’¼ Project Structure

```bash
project/
â”‚
â”œâ”€â”€ app.py                       ğŸ¯  Main Streamlit entry file (handles routing + sidebar)
â”‚
â”œâ”€â”€ single_audio_page.py          ğŸ§  Detect and explain deepfake for a single uploaded audio
â”œâ”€â”€ compare_page.py               âš–ï¸  Compare real vs fake audios side by side
â”œâ”€â”€ advanced_features_page.py     ğŸ§   Perform forensic and advanced acoustic analyses
â”‚
â”œâ”€â”€ cnn_lstm_deepfake_model.h5    ğŸ§©  Trained CNN-LSTM model (real vs fake classifier)
â”‚
â”œâ”€â”€ utils/                        âš™ï¸  Core utility modules
â”‚   â”œâ”€â”€ preprocessing.py          ğŸ”Š  Audio loading, trimming, feature extraction (MFCCs, etc.)
â”‚   â”œâ”€â”€ plotting.py               ğŸ“Š  Visualization helpers (waveform, spectrogram, MFCC plots)
â”‚   â”œâ”€â”€ model_utils.py            ğŸ§   Model loading, inference, and caching utilities
â”‚   â”œâ”€â”€ explainability.py         ğŸ”¥  Grad-CAM heatmaps and explainability visualizations
â”‚   â”œâ”€â”€ advanced_features.py      ğŸµ  Extracts advanced spectral and prosodic features
â”‚   â””â”€â”€ forensics.py              ğŸ”  Forensic metrics (pitch jitter, harmonicity, fade mismatch)
â”‚
â”œâ”€â”€ requirements.txt              ğŸ“¦  Dependency list for Streamlit or local environment
â”œâ”€â”€ README.md                     ğŸ“˜  Project documentation (overview, setup, usage)
â””â”€â”€ screenshots/ (optional)       ğŸ–¼ï¸  Demo images for README or Streamlit Cloud preview

---

ğŸ§© Model Overview

Architecture: CNN + LSTM hybrid

Input: Mel-spectrogram features (250 Ã— 64)

Output: Binary classification â†’ Real / Fake

Framework: TensorFlow / Keras

Trained On: Real vs synthetic speech samples from KYC-style datasets

---

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository

git clone https://github.com/yourusername/deepfake-audio-detector.git
cd deepfake-audio-detector

2ï¸âƒ£ Create a Virtual Environment (recommended)

python -m venv venv
source venv/bin/activate        # On Windows: venv\Scripts\activate

3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

4ï¸âƒ£ Run the Streamlit App

streamlit run app.py
---

ğŸ” Forensic Feature Set
| Feature                     | Description                                                           |
| --------------------------- | --------------------------------------------------------------------- |
| **Spectral Burst Fraction** | Detects sudden spectral spikes â€” may indicate synthesis artifacts     |
| **Fade Mismatch Score**     | Detects unnatural fade-in/out â€” signs of splicing or generation       |
| **Pitch Jitter Score**      | Measures unnatural pitch steadiness, common in TTS voices             |
| **Harmonicity Ratio**       | Checks periodic consistency â€” low values often mean vocoder artifacts |
| **Formant Variability**     | Low variability suggests vocoder smoothing or synthetic resonance     |

---

ğŸ“Š Output Examples

ğŸµ Waveform & Spectrogram

ğŸ”¥ Grad-CAM Heatmap (Model Attention)

ğŸ“ˆ Confidence Bar (Real vs Fake)

ğŸ” Forensic Scores Table

âš–ï¸ Side-by-Side Real vs Fake Comparison

(Add screenshots to /screenshots and link them here once deployed.)

---

â˜ï¸ Deployment

You can deploy this project seamlessly on:

ğŸŒ Streamlit Cloud

ğŸ¤— Hugging Face Spaces

App entry command:
streamlit run app.py

---

ğŸ§© Requirements
streamlit
librosa
numpy
matplotlib
tensorflow
scipy
praat-parselmouth
soundfile
scikit-learn

---

ğŸ§‘â€ğŸ’» Author

Capstone Project (Aug 2025 â€“ Oct 2025)
Developed by [Capstone team VIT-AP]
Focus: Deepfake Audio Detection for KYC Authentication Systems

---

ğŸŒŸ Future Enhancements

ğŸ¤ Integrate speaker verification embeddings

ğŸŒ Expand to multilingual datasets

ğŸ§  Add attention-based Grad-CAM++ visualization

ğŸª¶ Optimize lightweight model for mobile/on-edge deployment

---
ğŸ’¡ Emoji Legend
| Emoji | Meaning                  |
| :---: | :----------------------- |
|   ğŸ¯  | Main App Entry           |
|   ğŸ§  | Single Audio Page        |
|   âš–ï¸  | Comparison Page          |
|   ğŸ§   | Advanced / Forensic Page |
|   ğŸ”Š  | Audio Preprocessing      |
|   ğŸ“Š  | Plotting / Visualization |
|   ğŸ”¥  | Explainability           |
|   ğŸµ  | Advanced Features        |
|   ğŸ”  | Forensic Analysis        |
|   ğŸ“¦  | Dependencies             |
|   ğŸ“˜  | Documentation            |
|  ğŸ–¼ï¸  | Screenshots / Demo Media |
